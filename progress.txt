✅【1週目】完了
LeetCode SQL Easy〜Medium：20問以上完了

DockerでPostgreSQL＋pgAdmin環境構築：完了

SQL基礎演習（SELECT, WHERE, GROUP BY, ORDER BY 等）：完了

✅【2週目】完了
JOIN・サブクエリ・CTE：複数パターン演習済み

ダミーデータMockaroo活用：1000行以上の挿入完了

Explain Analyzeで基本的なチューニング確認：実践済み

✅【3週目】完了
ウィンドウ関数（ROW_NUMBER, RANK, SUM OVER）：複数演習完了

インデックス活用：作成＆速度差確認済み

CSV⇔DBの往復や保存もスムーズに

✅【4週目】進行中（ほぼ完了）
Python＋pandas＋matplotlibでのデータ処理：複合グラフ含め演習済み

CLIスクリプト化：cli.pyで処理メニュー化済み

スクリプト構成のモジュール分割・リファクタリング：config, query, scripts, output整備済み

kaggleのCSVデータインポート：スキーマ定義・データ投入完了

🔜【5週目】これから進む内容
✅ データクレンジング（欠損値・異常値）：チェック済み

🟡 集約・カテゴリ別分析：途中まで実行中

🔜 データパイプラインの自動化＆スケジューリング

🔜 Docker内でETLパターン構築（必要があれば Airflowやcronの導入）


✅ あなた専用【半年1000万円レンジ到達】超具体ウィークリータスク表

週	やること	目的	できること	活かし方
1週目	・LeetCode SQL Easy〜Medium 10問
・DockerでPostgreSQL＋pgAdmin環境構築	SQL基礎演習＋Docker環境整備	SQLの基礎操作とDBサーバ構築	ローカルで自由にDB構築→SQL演習ができ、環境の自由度が高まる
2週目	・JOIN・サブクエリ・CTEを中心にSQL演習10問
・100万行ダミーデータ作成（Mockarooなど）	複雑なクエリと大量データ経験	大規模データを扱う耐性獲得	業務データ（売上、在庫など）を正確にSQL処理できる
3週目	・ウィンドウ関数（ROW_NUMBER, RANK, SUM OVER）演習
・Explain Analyzeでクエリチューニング練習	パフォーマンス最適化練習	大量データでも速いSQLが書ける	実務でデータ抽出・分析処理を高速化できる
4週目	・SQLミニプロジェクト（例：売上ランキング作成、期間比較レポート）	総合力演習	簡易ビジネスレポート生成	実務の売上レポート・月次推移レポート作成に直結



週	やること	目的	できること	活かし方
5週目	・pandas基礎演習（CSV読込、基本加工）
・numpy演習（集約・統計演算）	データ加工基礎力強化	Pythonで大規模データを柔軟に加工できる	ETL（データ前処理）スクリプト作成力がつく
6週目	・pandasデータクレンジング（欠損値、異常値処理）
・カテゴリ集約（groupby）演習	クレンジング技術習得	前処理・集計を自動化できる	現場でデータの「使える化」を即実装できる
7週目	・PythonスクリプトをDockerfile化
・DockerコンテナからPostgreSQLへ書込	コンテナ開発練習	Python処理をDocker化→DB更新できる	本番を意識したクラウド運用に直結
8週目	・Pythonバッチのエラーハンドリング（try-except＋logging出力）	トラブル耐性強化	バッチ失敗時に自動ログ出力	障害復旧・運用保守力の底上げができる


週	やること	目的	できること	活かし方
9週目	・AWS無料枠設定（S3、EC2、Redshift）
・CLI操作練習（バケット作成、権限設定）	AWS基礎運用開始	CLIでリソース管理可能	大規模AWS環境でもスクリプト管理できる
10週目	・Python boto3でS3アップロード/ダウンロード
・Redshift COPY/UNLOAD演習	S3⇔Redshift連携理解	データロード＆バックアップ自動化	S3中継を活用した低コスト大量データ移動ができる
11週目	・ECSタスクにPythonコンテナ登録→定時実行設定	クラウド自動化理解	クラウド上でバッチ定時実行できる	現場のサーバレスバッチ移行プロジェクトに対応可能
12週目	・AWSリソースをTerraformで簡単にIaC演習（任意）	インフラコード化基礎理解	リソース構成をコードで管理できる	AWS案件の設計・構築・運用スピード爆上がり
週	やること	目的	できること	活かし方
13週目	・Docker ComposeでAirflow環境構築
・サンプルDAG動作確認	ワークフロー運用基礎	Airflow基本運用できる	バッチ運用標準ツール導入経験をアピール可能
14週目	・S3取込→加工→RedshiftロードDAG作成	実務フロー構築練習	一連パイプライン自動化	ETLフローを自動運用でき、現場即戦力
15週目	・エラー時リトライ設定・Slack通知設定	障害検知力強化	障害発生を即検知できる	SLA（サービスレベル保証）遵守ができる
16週目	・複数DAG依存設定（例：データロード後にレポート出力）	DAG間依存設計	複雑パイプライン制御可能	大規模システムのデータ連携も自力で組める

週	やること	目的	できること	活かし方
17週目	・売上・在庫データでスター型スキーマ設計	モデリング基礎理解	最適データ構造設計できる	分析パフォーマンス改善提案に直結
18週目	・Redshiftでデータモデリング実装（DDL作成）	実運用設計力養成	DB構築スキル獲得	モデリング提案・実装まで一人で対応できる
19週目	・DockerでMetabaseまたはSuperset構築	BI導入体験	クラウドBIツール運用できる	経営レポートや施策モニタリングシステム構築できる
20週目	・売上推移・顧客分析ダッシュボード作成	可視化・アウトプット力強化	KPIダッシュボード作成可能	経営層向け提案資料作成スキル獲得
週	やること	目的	できること	活かし方
21週目	・ETL×2、Airflow×1、モデリング×1成果物整備（GitHubアップ）	成果物準備完了	GitHubポートフォリオ公開可能	実績アピールで高単価案件・年収アップに直結
22週目	・LinkedIn / Wantedlyプロフィール作成	オファー受け体制整備	ヘッドハンティングされる状態	ハイクラス転職市場にアクセス可能
23週目	・案件応募（副業・正社員）5件以上	面接慣れ開始	案件参画への実践行動	実際の副業収入・年収アップに直結
24週目	・面接練習＆課題選考対策（必要に応じて）	応募確度最大化	案件獲得スキル磨き	高単価案件獲得・収入最大化を実現


✅ 手順まとめ

① Docker Desktopインストール　▶ https://www.docker.com/products/docker-desktop

② 任意のフォルダを作成
bash
コピーする編集する
mkdir docker_postgres_pgadmin
cd docker_postgres_pgadmin

③ docker-compose.ymlファイルを作成（内容は以下）
yaml
コピーする編集する
version: '3.8'
services:
  postgres:
    image: postgres:13
    container_name: postgres_container
    environment:
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: mypassword
      POSTGRES_DB: mydb
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data

  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin_container
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@example.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "8080:80"
    depends_on:
      - postgres

volumes:
  pgdata:

④ サービス起動コマンド
bash
コピーする編集する
docker-compose up -d

⑤ pgAdminにブラウザでアクセス
URL: http://localhost:8080
Email: admin@example.com
Password: admin

⑥ pgAdminからPostgreSQLに接続設定
Host: postgres
Port: 5432
Username: myuser
Password: mypassword

✅ トラブルシュート
接続できない場合、docker psでコンテナ起動状況確認
Hostは必ずpostgres（サービス名）に設定
環境変数（ユーザー名・パスワード）を間違えない

✅ 完成イメージ
Dockerコンテナ上でPostgreSQLサーバ＋ブラウザ管理ツール起動
ローカルに安全なデータベース環境を構築完了！

📌 注意
大企業（従業員250人以上 or 年収1000万ドル以上）ではDocker Desktopは有料
個人・学習・小規模企業利用なら完全無料でOK

🎯 この環境でできること
SQL演習（LeetCode、実務課題対応）
ダミーデータロード（100万行）
Docker運用スキル習得
PostgreSQL運用・管理スキル習得

✅ これをMacのメモアプリにそのままペーストすれば、いつでも見返せる「あなただけのマニュアル」になります！

